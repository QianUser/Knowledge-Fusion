[parameter]

# 文本匹配选取的关键词的数目
num_keywords = 100

# 决定属性匹配与数据匹配的相对惩罚，大于1，越大则属性匹配相对于数据匹配的惩罚越大
punish = 1.2

# 匹配阈值
threshold = 0.85


[data]

# 数据回调接口分页显示每页的大小
page_size = 20

# 文本表示返回的返回的词的表示的最大数量，必须大于num_keywords
max_text_count = 10000

# sentence-bert模型缓存的词向量数目
cache_embedding_size = 10000000

# 文本匹配缓存的字段表示最大数目
cache_text_rep_size = 10000

# 文本匹配缓存的字段统计最大数目
cache_text_statistics = 1000000

# 实例匹配缓存的字段统计最大数目
cache_instance_statistics = 1000000

# Asset缓存的表数据最大数目
cache_data_size = 10

# Asset缓存的表字段最大数目
cache_fields_size = 10000000



[process]

# 运行进程池的大小
# 这个值大了很耗内存
pool_size = 1


[ip]
# 获取资产字段属性的url
;get_url = http://123.59.211.135:7103/api/asset/data
get_url = http://127.0.0.1:8000/test/api/asset/data/

# 获取资产实际数据的url
;post_url = http://123.59.211.135:7103/api/asset/fields
post_url = http://127.0.0.1:8000/test/api/asset/fields/

# 回调的url
;result_url = http://123.59.211.135:7103/api/asset_relation/related_fields
result_url = http://127.0.0.1:8000/test/api/asset_relation/related_fields/

[celery]
# celery中异步的url
broker = redis://localhost:6379/0
# celery中异步的url
backend= redis://localhost:6379/0

[path]

# task_db数据库的路径
task_db_path = task.db

# 数据回调结果存储的路径
post_result_path = post_result.json

# idf词表
idf_path = idf.json

# 模型的选择
model = model.SentenceTransformerModel
;model = model.Word2VecModel
pre_sentence_transformer_model_name = stsb-roberta-base
tuned_sentence_transformer_model_path = knowledge_fusion/model/sentence-transformers-master/tuned_stsb-roberta-base

# 词向量路径
word2vec_path = knowledge_fusion/model/data/word2vec.txt

# 模拟数据路径
simulated_fields_path = knowledge_fusion/simulated_interface/data/fields.json
simulated_data_path = knowledge_fusion/simulated_interface/data/data
simulated_result_path = knowledge_fusion/simulated_interface/data/result

eval_data_path = knowledge_fusion/test/data
logic_name_var_path = logic_name_var.txt


[mode]
# 是否测试模式，如果是，值为true，否则为false
test = true